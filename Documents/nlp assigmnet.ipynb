{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e8287c-89f9-4df3-bd3f-3edaebb309fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Unigram Counts ---\n",
      "('i',): 1\n",
      "('love',): 1\n",
      "('learning',): 1\n",
      "('new',): 1\n",
      "('things',): 1\n",
      "('every',): 1\n",
      "('day',): 1\n",
      "\n",
      "--- Bigram Counts ---\n",
      "('i', 'love'): 1\n",
      "('love', 'learning'): 1\n",
      "('learning', 'new'): 1\n",
      "('new', 'things'): 1\n",
      "('things', 'every'): 1\n",
      "('every', 'day'): 1\n",
      "\n",
      "--- Trigram Counts ---\n",
      "('i', 'love', 'learning'): 1\n",
      "('love', 'learning', 'new'): 1\n",
      "('learning', 'new', 'things'): 1\n",
      "('new', 'things', 'every'): 1\n",
      "('things', 'every', 'day'): 1\n",
      "\n",
      "--- Bigram Probabilities ---\n",
      "P('i', 'love') = 1.0000\n",
      "P('love', 'learning') = 1.0000\n",
      "P('learning', 'new') = 1.0000\n",
      "P('new', 'things') = 1.0000\n",
      "P('things', 'every') = 1.0000\n",
      "P('every', 'day') = 1.0000\n",
      "\n",
      "--- Trigram Probabilities ---\n",
      "P('i', 'love', 'learning') = 1.0000\n",
      "P('love', 'learning', 'new') = 1.0000\n",
      "P('learning', 'new', 'things') = 1.0000\n",
      "P('new', 'things', 'every') = 1.0000\n",
      "P('things', 'every', 'day') = 1.0000\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a word or phrase (or type 'exit' to quit):  learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next word: new\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a word or phrase (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# ---------- Preprocessing ----------\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# ---------- N-gram Generation ----------\n",
    "def get_ngrams(tokens, n):\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "# ---------- Probability Computation ----------\n",
    "def compute_bigram_prob(bigram_counts, unigram_counts):\n",
    "    probs = defaultdict(float)\n",
    "    for (w1, w2), count in bigram_counts.items():\n",
    "        probs[(w1, w2)] = count / unigram_counts[(w1,)]\n",
    "    return probs\n",
    "\n",
    "def compute_trigram_prob(trigram_counts, bigram_counts):\n",
    "    probs = defaultdict(float)\n",
    "    for (w1, w2, w3), count in trigram_counts.items():\n",
    "        probs[(w1, w2, w3)] = count / bigram_counts[(w1, w2)]\n",
    "    return probs\n",
    "\n",
    "# ---------- Prediction ----------\n",
    "def predict_next_word(input_text, bigram_probs, trigram_probs):\n",
    "    tokens = preprocess(input_text)\n",
    "    \n",
    "    if len(tokens) >= 2:\n",
    "        w1, w2 = tokens[-2], tokens[-1]\n",
    "        candidates = {k: v for k, v in trigram_probs.items() if k[0] == w1 and k[1] == w2}\n",
    "        if candidates:\n",
    "            return max(candidates, key=candidates.get)[2]\n",
    "    \n",
    "    if len(tokens) >= 1:\n",
    "        w1 = tokens[-1]\n",
    "        candidates = {k: v for k, v in bigram_probs.items() if k[0] == w1}\n",
    "        if candidates:\n",
    "            return max(candidates, key=candidates.get)[1]\n",
    "    \n",
    "    return \"No prediction available.\"\n",
    "\n",
    "# ---------- Display Helper ----------\n",
    "def display_counts(title, counts):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    for k, v in counts.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "def display_probs(title, probs):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    for k, v in probs.items():\n",
    "        print(f\"P{str(k)} = {v:.4f}\")\n",
    "\n",
    "# ---------- Main Function ----------\n",
    "def main():\n",
    "    # ðŸ”¹ Sample corpus text (no file needed!)\n",
    "    text = text = \"I love learning new things every day.\"\n",
    "\n",
    "    \n",
    "    # Preprocess\n",
    "    tokens = preprocess(text)\n",
    "\n",
    "    # N-gram models\n",
    "    unigram_counts = Counter(get_ngrams(tokens, 1))\n",
    "    bigram_counts = Counter(get_ngrams(tokens, 2))\n",
    "    trigram_counts = Counter(get_ngrams(tokens, 3))\n",
    "\n",
    "    bigram_probs = compute_bigram_prob(bigram_counts, unigram_counts)\n",
    "    trigram_probs = compute_trigram_prob(trigram_counts, bigram_counts)\n",
    "\n",
    "    # Output\n",
    "    display_counts(\"Unigram Counts\", unigram_counts)\n",
    "    display_counts(\"Bigram Counts\", bigram_counts)\n",
    "    display_counts(\"Trigram Counts\", trigram_counts)\n",
    "\n",
    "    display_probs(\"Bigram Probabilities\", bigram_probs)\n",
    "    display_probs(\"Trigram Probabilities\", trigram_probs)\n",
    "\n",
    "    # Prediction\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter a word or phrase (or type 'exit' to quit): \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        prediction = predict_next_word(user_input, bigram_probs, trigram_probs)\n",
    "        print(\"Predicted next word:\", prediction)\n",
    "\n",
    "# Run the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce23eb61-2cdc-4190-a31c-07de4d71640c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'corpus.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# Load and preprocess corpus from file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcorpus.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     64\u001b[39m         text = f.read()\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# Preprocess\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'corpus.txt'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Preprocessing: lowercase, remove punctuation, tokenize\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Build n-grams\n",
    "def build_ngrams(tokens, n):\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "# Count frequencies\n",
    "def count_ngrams(ngrams):\n",
    "    counts = defaultdict(int)\n",
    "    for ng in ngrams:\n",
    "        counts[ng] += 1\n",
    "    return counts\n",
    "\n",
    "# Compute bigram probabilities with explanation\n",
    "def compute_bigram_prob(bigram_counts, unigram_counts):\n",
    "    probs = defaultdict(float)\n",
    "    print(\"\\n--- Bigram Probabilities ---\")\n",
    "    for (w1, w2), count in bigram_counts.items():\n",
    "        prob = count / unigram_counts[(w1,)]\n",
    "        probs[(w1, w2)] = prob\n",
    "        print(f\"P({w2} | {w1}) = {count} / {unigram_counts[(w1,)]} = {prob:.3f}\")\n",
    "    return probs\n",
    "\n",
    "# Compute trigram probabilities with explanation\n",
    "def compute_trigram_prob(trigram_counts, bigram_counts):\n",
    "    probs = defaultdict(float)\n",
    "    print(\"\\n--- Trigram Probabilities ---\")\n",
    "    for (w1, w2, w3), count in trigram_counts.items():\n",
    "        prob = count / bigram_counts[(w1, w2)]\n",
    "        probs[(w1, w2, w3)] = prob\n",
    "        print(f\"P({w3} | {w1} {w2}) = {count} / {bigram_counts[(w1, w2)]} = {prob:.3f}\")\n",
    "    return probs\n",
    "\n",
    "# Predict next word\n",
    "def predict_next_word(input_text, bigram_probs, trigram_probs):\n",
    "    input_tokens = input_text.lower().split()\n",
    "    if len(input_tokens) >= 2:\n",
    "        context = tuple(input_tokens[-2:])\n",
    "        candidates = {k[2]: v for k, v in trigram_probs.items() if k[:2] == context}\n",
    "        if candidates:\n",
    "            max_prob = max(candidates.values())\n",
    "            best_words = [word for word, prob in candidates.items() if prob == max_prob]\n",
    "            return best_words\n",
    "    if len(input_tokens) >= 1:\n",
    "        context = tuple([input_tokens[-1]])\n",
    "        candidates = {k[1]: v for k, v in bigram_probs.items() if k[0] == context[0]}\n",
    "        if candidates:\n",
    "            max_prob = max(candidates.values())\n",
    "            best_words = [word for word, prob in candidates.items() if prob == max_prob]\n",
    "            return best_words\n",
    "    return [\"No prediction available\"]\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess corpus from file\n",
    "    with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Preprocess\n",
    "    tokens = preprocess(text)\n",
    "\n",
    "    # Build n-grams\n",
    "    unigrams = build_ngrams(tokens, 1)\n",
    "    bigrams = build_ngrams(tokens, 2)\n",
    "    trigrams = build_ngrams(tokens, 3)\n",
    "\n",
    "    # Count frequencies\n",
    "    unigram_counts = count_ngrams(unigrams)\n",
    "    bigram_counts = count_ngrams(bigrams)\n",
    "    trigram_counts = count_ngrams(trigrams)\n",
    "\n",
    "    # Print counts\n",
    "    print(\"--- Unigram Counts ---\")\n",
    "    for k, v in unigram_counts.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\n--- Bigram Counts ---\")\n",
    "    for k, v in bigram_counts.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\n--- Trigram Counts ---\")\n",
    "    for k, v in trigram_counts.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    # Calculate and show probabilities\n",
    "    bigram_probs = compute_bigram_prob(bigram_counts, unigram_counts)\n",
    "    trigram_probs = compute_trigram_prob(trigram_counts, bigram_counts)\n",
    "\n",
    "    # Prediction\n",
    "    print(\"\\n--- Next Word Prediction ---\")\n",
    "    while True:\n",
    "        inp = input(\"Enter a word or phrase (or 'exit' to quit): \")\n",
    "        if inp.lower() == \"exit\":\n",
    "            break\n",
    "        predictions = predict_next_word(inp, bigram_probs, trigram_probs)\n",
    "        print(\"Predicted next word(s):\", predictions)\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba62f817-2bb7-42ab-9dbb-1033e4eb0180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
